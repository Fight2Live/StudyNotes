# 统计学习

统计学习（statistical learning）是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科。统计学习也成为统计机器学习。

> Herbert A.Simon曾对“学习”给出以下定义：“如果一个系统能够通过执行某个过程来改进它的性能，这就是学习”

# 主要特点

1. 以计算机及网络为平台

2. 以数据为研究对象，是数据驱动的学科

3. 目的是对数据进行预测与分析

4. 以方法为中心，来构建模型并应用模型进行预测与分析

5. 是概率、统计学、信息论、计算理论、最优化理论及计算机科学等多领域的交叉学科，并逐步形成肚子的理论体系与方法论



# 实现统计学习方法的步骤如下：

1. 得到一个有限的训练数据集和（获取数据集）

2. 确定包含所有可能的模型的假设空间，即学习模型的集合

3. 确定模型选择的准则，即学习的策略（损失函数，模型评估依据）

4. 实现求解最优模型的算法，即学习的算法（模型调优）

5. 通过学习方法选择最优模型

6. 利用学习的最优模型对新数据进行预测或分析（模型应用）



# 模型分类

        统计学习是一个范围宽阔、内容繁多、应用广泛的领域，并不存在一个统一的理论体系可以涵盖所有内容

## 基本分类

- 监督学习

        指从标注数据中学习预测模型。

        **本质是学习输入到输出的映射的统计规律**。

        多用来分类与预测。

- 无监督学习

        从没有标注的数据中学习预测模型。

        **本质是学习数据中的统计规律或潜在结构。**

        多用来实现数据的聚类、降维或概率估计。

- 强化学习

        指智能系统在与环境的连续互动中学习最优行为策略。

        **本质是学习最优的序贯决策。**

        

- 半监督学习与主动学习

        半监督学习指利用标注数据和未标注数据进行学习预测模型。

        主动学习指机器不断主动给出实例让教师进行标注，然后利用标注的数据学习预测模型。（把测试数据自动标记后添加进训练数据中重新学习）

        更接近监督学习

## 按模型

- 概率模型与非概率模型

- 线性模型与非线性模型

- 参数化模型与非参数化模型



## 按算法

- 在线学习

        每次接受一个样本进行预测，之后学习，并不断重复。

        如利用随机梯度下降的感知机算法

- 批量学习

        一次接受所有数据，学习模型，之后进行预测。

       

         在线学习通常比批量学习更难，很难学到预测准确率更高的模型，因为每次模型更新中，可利用的数据有限。



## 按技巧

- 贝叶斯学习

- 核方法



# 三要素

统计学习方法都是由模型、策略和算法构成的，可以简单的表示为

                                                    $方法=模型+策略+算法$



## 模型

        在监督学习过程中，模型就是所要学习的条件概率分布或决策函数。



## 策略

        统计学习的目的在于从假设空间中选取最优模型。

### 函数

       **损失函数**度量模型一次预测的好坏。

       **风险函数**度量平均意义下模型预测的好坏。

       学习的目标就是选择期望风险最小的模型。其实就是模型的优化原理。

### 最小化

        在假设空间、损失函数以及训练数据集确定的情况下，经验风险函数式就可以确定，所以**经验风险最小化（empirical risk minimization, ERM）的策略**认为，经验风险最小的模型是最优模型：

                                              $\min_{f \in F}\frac{1}{N} \sum_{i=1}^{N}L(y_i,f(x_i))$

        比如极大似然估计就是经验风险最小化的一个例子。

        但是当样本容量很小时，会产生过拟合



        **结构风险最小化（structural risk minimization, SRM）策略**是为了防止过拟合而提出的，**它等价于正则化**。

        结构风险在经验风险上，加上了表示模型复杂度的正则化项和罚项，即经验风险与模型复杂度的综合考量。

                                         $R_{srm}(f)=\frac{1}{N} \sum_{i=1}^{N}L(y_i,f(x_i))+\lambda Jf)$

        结构风险小的模型往往对训练数据以及未知的测试数据都有较好的效果。所以SRM认为结构风险最小的是最优模型：

                                         $\min_{f \in F}\frac{1}{N} \sum_{i=1}^{N}L(y_i,f(x_i))+\lambda Jf)$



**这样，监督学习问题就变成了经验风险或结构风险函数的最优化问题，经验或结构风险函数就是最优化的目标函数**





## 算法

        指学习模型的具体计算方法。


