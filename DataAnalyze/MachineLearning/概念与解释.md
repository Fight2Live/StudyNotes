# 概念与解释



## 算法分类

### 监督学习：

在监督学习的过程中，我们只需要给定输入样本集，机器就可以从中推演出指定目标变量的可能结果。

**根据已有的数据集，知道输入和输出结果之间的关系。根据这种已知的关系，训练得到一个最优的模型。**

需要有样本集，通过分析样本集中的 **特征** 和 **标签** 去得到一个演算模型，可以由已知的特征去得到未知的标签。

#### 分类算法：

1. K-NN，决策树，朴素贝叶斯，逻辑回归，支持向量机，Adaboost





### 无监督学习：

与监督学习相反，它不需要提前给定样本集去训练模型。它可以把标签未知的数据，根据一定规则 **聚拢** 起来，形成一簇又一簇。

**即，我们不知道数据集中数据、特征之间的关系，而是要根据聚类或一定的模型得到数据之间的关系。**

#### 聚类算法：

1. K-Mean，Apriori，FP-growth，





## 如何选择合适的算法？

### 1、首先考虑使用机器学习算法的**目的** 。

如果想要预测目标变量的值，则可以选择监督学习算法；否则选择无监督学习



### 2、确定目标变量类型

如果目标变量是离散型，如是/否，A/B/C，红/绿/蓝等，可以选择**分类器算法**；

如果目标变量是连续型数值，如0.0~100.00，-999~999等，则需要选择**回归算法**。

如果不想预测目标变量的值，则可以选择**无监督学习算法** 。

1. 进一步分析是否需要将数据划分为离散的组。如果这是唯一需求，则使用聚类算法；
2. 如果还需要估计数据与每个分组的相似程度，则需要使用密度估计算法。
3. 数据分析



### 3、了解数据特性

主要了解数据的以下特性：

1. 特征值是离散型变量还是连续型变量？
2. 特征值中是否存在缺失值？何种原因造成的缺失？
3. 数据中是否存在异常值？
4. 某个特征发生的频率如何？
5. 等等……

通过分析数据，我们可以缩短选择机器学习算法的时间，选择到更加合适的，性能更好的，并让思路更加清晰



## 衡量指标

​		算法模型是多种多样的。很多时候对一个需求进行预测或分类时，我们有很多种选择，那么要如何去衡量某个算法对当前场景的效果最好呢，往往都会有一些指标来提供衡量标准。除去指标外还有算法本身的特性也会有所影响

> ​		内容在很大程度都参考 [机器学习评价指标大汇总](https://zhaokv.com/machine_learning/2016/03/ml-metric.html)
>
> ​		与书本：《Hands-On Machine Learning with Scikit-Learn,Keras,and TensorFlow,2nd Edition》作者：Aurelien Geron

### 一、分类



#### 1、常用术语

​	1）True positives(真正，TP): 被正确地划分为正例的个数，即实际为正例且被分类器划分为正例的实例数（样本数）；

​	2）False positives(假正，FP): 被错误地划分为正例的个数，即实际为负例但被分类器划分为正例的实例数 → **误报**；

​	3）False negatives(假负，FN):被错误地划分为负例的个数，即实际为正例但被分类器划分为负例的实例数 → **漏报**；

​	4）True negatives(真负，TN): 被正确地划分为负例的个数，即实际为负例且被分类器划分为负例的实例数。

|          |      | 预测类别 |      | 总计 |
| -------- | ---- | -------- | ---- | ---- |
| 实际类别 |      | Yes      | No   |      |
|          | Yes  | TP       | FN   | P    |
|          | No   | FP       | TN   | N    |
|          | 总计 | P'       | N'   | P+N  |



#### 2、常规评价指标

##### 	（1）准确率（Accuracy）

​			正确率是很常见的评价指标，即在所有待分类的样本中，被正确分类的样本比例
$$
Accuracy = \frac{TP + TN}{P + N}
$$

##### 	（2）精确率（precision）

​			**精确率**是对**预测结果**而言的，表示被分为正例的样本中，实际也是正例的样本比例
$$
Precision = \frac{TP}{TP+FP}
$$

##### 	（3）召回率（Recall）

​			而**召回率就**是对**训练样本**而言的，表示所有实际为正例的样本里，也被划分为正例的数量占比
$$
Recall = \frac{TP}{TP+FN}
$$

> 假设我们手上有60个正样本，40个负样本，我们要找出所有的正样本，系统查找出50个，其中只有40个是真正的正样本，计算上述各指标。
>
> 
>
> **准确率**(accuracy) = 预测对的/所有 = (TP+TN)/(P+N) = 70%
> **精确率**(precision) = TP/(TP+FP) = 80%
> **召回率**(recall) = TP/(TP+FN) = 2/3



##### 	（4）其他评价指标

- 鲁棒性：处理缺失值和异常值的能力
- 可解释性：分类器预测标准的可理解性。像决策树产生的规则就是易理解的，而神经网络则是很多个不易理解的参数。
- 可扩展性：处理大数据集的能力
- 计算速度：分类器训练和预测所需要的时间



​		对于某个具体的分类器而言，我们不可能同时提高所有上面介绍的指标，当然，如果一个分类器能正确分对所有的实例，那么各项指标都已经达到最优，但这样的分类器往往不存在。比如地震预测，没有谁能准确预测地震的发生，但我们能容忍一定程度的误报，假设1000次预测中，有5次预测为发现地震，其中一次真的发生了地震，而其他4次为误报，那么正确率从原来的999/1000=99.9%下降到996/1000=99.6，但召回率从0/1=0%上升为1/1=100%，这样虽然谎报了几次地震，但真的地震来临时，我们没有错过，这样的分类器才是我们想要的，在一定正确率的前提下，我们要求分类器的召回率尽可能的高。



#### 3、ROC曲线



#### 4、对数损失



#### 5、铰链损失



#### 6、混淆矩阵



#### 7、Kappa系数



#### 8、海明距离



#### 9、杰卡德相似系数



#### 10、多标签排序



### 二、回归



### 三、聚类